{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key setup\n",
    "api_key = 'XLrT4TY4C8ZdIFQOMri1QX6Cc'\n",
    "api_secret_key = 'nFdnp9YT30Omojj9JZdtqD6j6qKP6vvuo65FjLOt6Fe0eotwpZ'\n",
    "access_token = '3083368926-c7fXpsH0k1Hrqs6bNe7954RMMp7viwgK7paRuHX'\n",
    "access_token_secret = 'bTTr0tiF4Xizcnjj7gGS1efzhSN5Co8Cgcc0P1cHjMXeF'\n",
    "# Bearer token from Twitter API v2\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAJttvwEAAAAAve3ZMFPG3IVh5poNuakDQUxLo%2Fw%3DcdUn78VL26nE15hTVzu9hjKEl1raNd8xRnvL00uVVloJABXMSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp   Author_ID  \\\n",
      "0 2024-09-16 10:35:28+00:00   185086854   \n",
      "1 2024-09-16 10:33:44+00:00    62797848   \n",
      "2 2024-09-16 10:32:35+00:00   538940166   \n",
      "3 2024-09-16 10:24:40+00:00  2790753125   \n",
      "4 2024-09-16 10:22:40+00:00  1431482203   \n",
      "\n",
      "                                               Tweet  \n",
      "0  RT @Fuel_YourGrowth: Leaving a toxic workplace...  \n",
      "1  You may already be aware of the high level of ...  \n",
      "2  RT @Fuel_YourGrowth: Leaving a toxic workplace...  \n",
      "3  RT @kimbafuzz: This echos some of my own feeli...  \n",
      "4  RT @Fuel_YourGrowth: Leaving a toxic workplace...  \n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import logging\n",
    "\n",
    "# Create client for Twitter API v2\n",
    "client = tweepy.Client(bearer_token=bearer_token)\n",
    "\n",
    "# Query tweets using the v2 API\n",
    "query = 'attrition risk OR employee turnover OR workplace stress OR HR issues lang:en'\n",
    "response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=100)\n",
    "\n",
    "# Store tweet details in a DataFrame\n",
    "tweet_data = []\n",
    "for tweet in response.data:\n",
    "    tweet_data.append([tweet.created_at, tweet.author_id, tweet.text])\n",
    "\n",
    "df_tweets = pd.DataFrame(tweet_data, columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "\n",
    "# Display first few rows\n",
    "print(df_tweets.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet  \\\n",
      "0  RT @Fuel_YourGrowth: Leaving a toxic workplace...   \n",
      "1  You may already be aware of the high level of ...   \n",
      "2  RT @Fuel_YourGrowth: Leaving a toxic workplace...   \n",
      "3  RT @kimbafuzz: This echos some of my own feeli...   \n",
      "4  RT @Fuel_YourGrowth: Leaving a toxic workplace...   \n",
      "\n",
      "                                       Cleaned_Tweet  \n",
      "0  rt  leaving a toxic workplace is an act of bra...  \n",
      "1  you may already be aware of the high level of ...  \n",
      "2  rt  leaving a toxic workplace is an act of bra...  \n",
      "3  rt  this echos some of my own feelings this be...  \n",
      "4  rt  leaving a toxic workplace is an act of bra...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n",
    "    text = re.sub(r'#', '', text)        # Remove hashtags\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters\n",
    "    return text.strip().lower()\n",
    "\n",
    "df_tweets['Cleaned_Tweet'] = df_tweets['Tweet'].apply(clean_tweet)\n",
    "print(df_tweets[['Tweet', 'Cleaned_Tweet']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet Sentiment\n",
      "0  rt  leaving a toxic workplace is an act of bra...  POSITIVE\n",
      "1  you may already be aware of the high level of ...  POSITIVE\n",
      "2  rt  leaving a toxic workplace is an act of bra...  POSITIVE\n",
      "3  rt  this echos some of my own feelings this be...  NEGATIVE\n",
      "4  rt  leaving a toxic workplace is an act of bra...  POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment-analysis pipeline\n",
    "sentiment_model = pipeline('sentiment-analysis')\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df_tweets['Sentiment'] = df_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "\n",
    "print(df_tweets[['Cleaned_Tweet', 'Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22288\\472202984.py:9: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the sentiment occurrences\n",
    "sentiment_counts = df_tweets['Sentiment'].value_counts()\n",
    "\n",
    "# Plot the sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution of Tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "X = vectorizer.fit_transform(df_tweets['Cleaned_Tweet'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_features = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.88      1.00      0.93        14\n",
      "    POSITIVE       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.94      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have labels for training\n",
    "y = df_tweets['Sentiment'] \n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fetch time: 0.68 seconds\n",
      "INFO:root:Process time: 0.00 seconds\n",
      "INFO:root:Feature extraction time: 0.00 seconds\n",
      "INFO:root:Prediction time: 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @Fuel_YourGrowth: Leaving a toxic workplace is an act of bravery, not a sign of defeat!\n",
      "\n",
      "According to MIT, having a toxic work culture iâ€¦\n",
      "Prediction: POSITIVE\n",
      "\n",
      "Tweet: You may already be aware of the high level of service we provide to support our clients with regards toÂ #HRÂ andÂ #EmploymentLawÂ issues. But did you know we also offer specialist services in #Outplacement? Get in touch to find out more https://t.co/eMnQ5vaujV ðŸ”— https://t.co/KZgyklpbiu\n",
      "Prediction: POSITIVE\n",
      "\n",
      "Tweet: RT @Fuel_YourGrowth: Leaving a toxic workplace is an act of bravery, not a sign of defeat!\n",
      "\n",
      "According to MIT, having a toxic work culture iâ€¦\n",
      "Prediction: POSITIVE\n",
      "\n",
      "Tweet: RT @kimbafuzz: This echos some of my own feelings. This being the anniversary of BMâ€™s passingâ€¦. I kinda wish it had just been about remembeâ€¦\n",
      "Prediction: NEGATIVE\n",
      "\n",
      "Tweet: RT @Fuel_YourGrowth: Leaving a toxic workplace is an act of bravery, not a sign of defeat!\n",
      "\n",
      "According to MIT, having a toxic work culture iâ€¦\n",
      "Prediction: POSITIVE\n",
      "\n",
      "Processed 5 tweets. Exiting...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def process_tweets():\n",
    "    tweet_count = 0\n",
    "    max_tweets = 5\n",
    "    \n",
    "    while tweet_count < max_tweets:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Fetch new tweets\n",
    "            fetch_start = time.time()\n",
    "            response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=10)\n",
    "            if response.data is None:\n",
    "                logger.warning(\"No tweets found.\")\n",
    "                time.sleep(60)  # Sleep and retry if no tweets\n",
    "                continue\n",
    "            fetch_time = time.time() - fetch_start\n",
    "            \n",
    "            # Process and clean tweets\n",
    "            process_start = time.time()\n",
    "            new_tweets = pd.DataFrame([[tweet.created_at, tweet.author_id, tweet.text] for tweet in response.data], columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "            new_tweets['Cleaned_Tweet'] = new_tweets['Tweet'].apply(clean_tweet)\n",
    "            process_time = time.time() - process_start\n",
    "            \n",
    "            # Extract features\n",
    "            feature_start = time.time()\n",
    "            new_features = vectorizer.transform(new_tweets['Cleaned_Tweet'])\n",
    "            df_new_features = pd.DataFrame(new_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "            feature_time = time.time() - feature_start\n",
    "            \n",
    "            # Predict attrition risk\n",
    "            predict_start = time.time()\n",
    "            predictions = model.predict(df_new_features)\n",
    "            predict_time = time.time() - predict_start\n",
    "            \n",
    "            # Output predictions and increment tweet_count\n",
    "            for tweet, prediction in zip(new_tweets['Tweet'], predictions):\n",
    "                if tweet_count < max_tweets:\n",
    "                    print(f\"Tweet: {tweet}\\nPrediction: {prediction}\\n\")\n",
    "                    tweet_count += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Log times\n",
    "            logger.info(f\"Fetch time: {fetch_time:.2f} seconds\")\n",
    "            logger.info(f\"Process time: {process_time:.2f} seconds\")\n",
    "            logger.info(f\"Feature extraction time: {feature_time:.2f} seconds\")\n",
    "            logger.info(f\"Prediction time: {predict_time:.2f} seconds\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred: {e}\")\n",
    "            break\n",
    "        \n",
    "        if tweet_count < max_tweets:\n",
    "            # Sleep for a while before fetching new tweets\n",
    "            time.sleep(60)  # Fetch new tweets every 1 minute\n",
    "    \n",
    "    print(\"Processed 5 tweets. Exiting...\")\n",
    "\n",
    "# Run the real-time processing function\n",
    "process_tweets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LLM --> GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment-analysis pipeline\n",
    "sentiment_model = pipeline('sentiment-analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet LLM_Sentiment\n",
      "0  rt  leaving a toxic workplace is an act of bra...      POSITIVE\n",
      "1  you may already be aware of the high level of ...      POSITIVE\n",
      "2  rt  leaving a toxic workplace is an act of bra...      POSITIVE\n",
      "3  rt  this echos some of my own feelings this be...      NEGATIVE\n",
      "4  rt  leaving a toxic workplace is an act of bra...      POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# Apply sentiment analysis using the LLM\n",
    "df_tweets['LLM_Sentiment'] = df_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "\n",
    "print(df_tweets[['Cleaned_Tweet', 'LLM_Sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Initialize GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_Tweet  \\\n",
      "0  rt  leaving a toxic workplace is an act of bra...   \n",
      "1  you may already be aware of the high level of ...   \n",
      "2  rt  leaving a toxic workplace is an act of bra...   \n",
      "3  rt  this echos some of my own feelings this be...   \n",
      "4  rt  leaving a toxic workplace is an act of bra...   \n",
      "\n",
      "                                    Generated_Topics  \n",
      "0  rt  leaving a toxic workplace is an act of bra...  \n",
      "1  you may already be aware of the high level of ...  \n",
      "2  rt  leaving a toxic workplace is an act of bra...  \n",
      "3  rt  this echos some of my own feelings this be...  \n",
      "4  rt  leaving a toxic workplace is an act of bra...  \n"
     ]
    }
   ],
   "source": [
    "def generate_topics(text, max_input_length=50, max_new_tokens=20):\n",
    "    # Truncate the input text if it's longer than the max_input_length\n",
    "    inputs = tokenizer.encode(text[:max_input_length], return_tensors='pt')\n",
    "    \n",
    "    # Generate topics with a set number of new tokens\n",
    "    outputs = model.generate(inputs, max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply topic generation to the cleaned tweets\n",
    "df_tweets['Generated_Topics'] = df_tweets['Cleaned_Tweet'].apply(generate_topics)\n",
    "\n",
    "# Display the results\n",
    "print(df_tweets[['Cleaned_Tweet', 'Generated_Topics']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: RT @mercer: When political discourse takes place in the office, it can trigger workplace incivility resulting in higher rates of stress amoâ€¦\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: RT @BirkbeckUoL: Do you know the difference between stress and #burnout? \n",
      "\n",
      "In this #BirkbeckExplains, Prof Almuth McDowall &amp; Dr @kevinteohrâ€¦\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: Do you know the difference between stress and #burnout? \n",
      "\n",
      "In this #BirkbeckExplains, Prof Almuth McDowall &amp; Dr @kevinteohrh talk about the tell-tale differences between the two in the workplace and beyond. ðŸ§   https://t.co/OZucSU9pcN \n",
      "\n",
      "@BBK_Business @bbkpsychology\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: When political discourse takes place in the office, it can trigger workplace incivility resulting in higher rates of stress among employees. Explore ways in which employers can foster positive work behaviors to uphold workplace civility. https://t.co/akuyPRsgu4 #wellbeing https://t.co/72NnviWzC4\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: Another symptom of my brain not constantly being in stress mode from a toxic workplace - I get to really feel my feelings, and just HOW MUCH I was repressing, especially from the last couple of years. I finally have the space to catch up with the pieces that were left behind...\n",
      "LLM Sentiment: NEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_tweets_with_llm():\n",
    "    tweet_count = 0  # Counter for the number of tweets processed\n",
    "    \n",
    "    while tweet_count < 5:  # Loop until 5 tweets are processed\n",
    "        # Fetch new tweets\n",
    "        response = client.search_recent_tweets(query=query, tweet_fields=['created_at', 'author_id', 'text'], max_results=10)\n",
    "        \n",
    "        # Process and clean tweets\n",
    "        new_tweets = pd.DataFrame([[tweet.created_at, tweet.author_id, tweet.text] for tweet in response.data], columns=['Timestamp', 'Author_ID', 'Tweet'])\n",
    "        new_tweets['Cleaned_Tweet'] = new_tweets['Tweet'].apply(clean_tweet)\n",
    "        \n",
    "        # Apply LLM sentiment analysis\n",
    "        new_tweets['LLM_Sentiment'] = new_tweets['Cleaned_Tweet'].apply(lambda tweet: sentiment_model(tweet)[0]['label'])\n",
    "        \n",
    "        # Output results\n",
    "        for tweet, sentiment in zip(new_tweets['Tweet'], new_tweets['LLM_Sentiment']):\n",
    "            print(f\"Tweet: {tweet}\\nLLM Sentiment: {sentiment}\\n\")\n",
    "            tweet_count += 1\n",
    "            if tweet_count >= 5:\n",
    "                break\n",
    "        \n",
    "        # If 5 tweets have been printed, exit the loop\n",
    "        if tweet_count >= 5:\n",
    "            break\n",
    "\n",
    "# Run the real-time processing function with LLM\n",
    "process_tweets_with_llm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
