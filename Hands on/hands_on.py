# -*- coding: utf-8 -*-
"""Hands On.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LrY9pSplmhEcZmj3j_ogLIQ8bbmzzK7R

â€¢	Load Dataset:
"""

import pandas as pd

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/MFG10YearTerminationData.csv')

# Display the first few rows of the dataset
print(data.head())

"""- Display Column Names

"""

# Display column names
print(data.columns)

"""- Data Preprocessing"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Handling missing values if any
data = data.dropna()

# Convert the date column to datetime format
data['terminationdate_key'] = pd.to_datetime(data['terminationdate_key'])

# Extract year, month, and day from the date
data['year'] = data['terminationdate_key'].dt.year
data['month'] = data['terminationdate_key'].dt.month
data['day'] = data['terminationdate_key'].dt.day

# Drop the original date column
data = data.drop(columns=['terminationdate_key'])

# Encoding categorical variables
label_encoder = LabelEncoder()
data['target_column'] = label_encoder.fit_transform(data['STATUS'])

# Encode other categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns

for col in categorical_columns:
    data[col] = label_encoder.fit_transform(data[col])

# Splitting features and target
X = data.drop(columns=['target_column'])
y = data['target_column']

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""- Build and Train the Deep Learning Model"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Building the model
model = Sequential()
model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification; use 'softmax' for multi-class

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

"""- Evaluate the Model"""

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.2f}')

"""- Visualizing Training History"""

import matplotlib.pyplot as plt

# Plotting training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plotting training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

"""- Visualizing Confusion Matrix"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predicting the labels on the test set
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype(int).reshape(-1)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

